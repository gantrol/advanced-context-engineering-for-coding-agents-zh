[← Back to README](../README.md)

## The Stanford Study & Sean Grove's Revelation

### Sean Grove: "Specs Are The New Code"

Sean argued that we're all *vibe coding wrong*. 

Think about it: You chat with an AI agent for two hours, carefully specifying what you want, iterating on the approach, refining the solution... then you throw away all those prompts and commit only the final code.

That's like a Java developer compiling a JAR and checking in the compiled binary while throwing away the source.

> In two years, you'll be opening Python files in your IDE with about the same frequency that, today, you might open up a hex editor to read assembly (which, for most of us, is never).

Sean proposes that in the AI future, **the specs will become the real code**. The implementation is just a build artifact.

### The Stanford Study: Why AI Tools Fail

Yegor's team analyzed commits from 100,000 developers and found sobering results:

1. **AI tools often lead to massive rework** - The perceived productivity gains are often illusory when you factor in the fixes and refactoring needed later.

2. **AI tools work well for greenfield, fail for brownfield** - Starting fresh? Great. Working in an existing codebase? Good luck.

The data shows what we all feel: current approaches to AI coding aren't cutting it for real work.

### The Gap We Need to Bridge

What teams need:
* AI that works well in brownfield codebases
* AI that solves complex problems
* No slop
* Mental alignment across the team

What they're getting:
* Demos that work in toy repos
* Solutions that create more problems
* Tech debt factories
* Teams losing track of their own codebases

The gap isn't going to be bridged by waiting for smarter models. It's going to be bridged by being smarter about how we use today's models.

[← From 12-Factor to Context Engineering](01-from-12factor-to-context-engineering.md) | [Our Weird Journey →](03-our-weird-journey.md)